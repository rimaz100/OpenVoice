{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import sys\n",
    "\n",
    "from artst.tasks.artst import ArTSTTask\n",
    "from artst.models.artst import ArTSTTransformerModel\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "\n",
    "from fairseq import checkpoint_utils, utils\n",
    "\n",
    "\n",
    "checkpoint = torch.load('.../ArTST-hf/MGB2_ASR.pt')  # path to change\n",
    "checkpoint['cfg']['task'].t5_task = 's2t' # or \"s2t\" for asr\n",
    "checkpoint['cfg']['task'].data = '.../ArTST-hf'  # path to change\n",
    "task = ArTSTTask.setup_task(checkpoint['cfg']['task'])\n",
    "task.args.bpe_tokenizer = '.../ArTST-hf/asr_spm.model'  # path to change\n",
    "\n",
    "model = ArTSTTransformerModel.build_model(checkpoint['cfg']['model'], task)\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lms, _ = checkpoint_utils.load_model_ensemble([lm_path], arg_overrides=overrides, task=None)\n",
    "lms = [None]\n",
    "lm_weight = None\n",
    "models = [model]\n",
    "\n",
    "extra_gen_cls_kwargs = {\"lm_model\": lms[0], \"lm_weight\": lm_weight}\n",
    "generator = task.build_generator([model], task.args, extra_gen_cls_kwargs=extra_gen_cls_kwargs)\n",
    "\n",
    "source, sr = torchaudio.load('....')\n",
    "padding_mask = (torch.BoolTensor(source.shape).fill_(False))\n",
    "\n",
    "assert sr == 16000\n",
    "sample = {\n",
    "    \"net_input\": {\n",
    "        \"source\": source,\n",
    "        \"padding_mask\": padding_mask,\n",
    "        \"task_name\": \"s2t\",\n",
    "    }\n",
    "}\n",
    "hypos = task.inference_step(\n",
    "    generator,\n",
    "    models,\n",
    "    sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbols_to_strip_from_output(generator):\n",
    "    if hasattr(generator, \"symbols_to_strip_from_output\"):\n",
    "        return generator.symbols_to_strip_from_output\n",
    "    else:\n",
    "        return {generator.eos}\n",
    "\n",
    "def decode_fn(x):\n",
    "    if bpe is not None:\n",
    "        x = bpe.decode(x)\n",
    "    if tokenizer is not None:\n",
    "        x = tokenizer.decode(x)\n",
    "    return x\n",
    "\n",
    "tokenizer = None\n",
    "bpe = task.build_bpe(task.args)\n",
    "\n",
    "hypo_tokens, hypo_str, alignment = utils.post_process_prediction(\n",
    "    hypo_tokens=hypos[0][0][\"tokens\"].int().cpu(),\n",
    "    src_str=\"\",\n",
    "    alignment=hypos[0][0][\"alignment\"],\n",
    "    align_dict=None,\n",
    "    tgt_dict=task.dicts['text'],\n",
    "    remove_bpe=None,\n",
    "    extra_symbols_to_ignore=get_symbols_to_strip_from_output(generator)\n",
    ")\n",
    "decode_fn(hypo_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
